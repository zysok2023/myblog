# 内核参数调优
[参考](https://www.brendangregg.com/linuxperf.html)
## 工具
![ Linux 可观测性工具](https://cdn.jsdelivr.net/gh/zysok2023/cloudImg/blogs/picture/linux_observability_tools.png)

![Linux 基准测试工具](https://cdn.jsdelivr.net/gh/zysok2023/cloudImg/blogs/picture/linux_benchmarking_tools.png)

![Linux 静态性能分析工具](https://cdn.jsdelivr.net/gh/zysok2023/cloudImg/blogs/picture/linux_static_tools.png)

![ Linux 调优工具](https://cdn.jsdelivr.net/gh/zysok2023/cloudImg/blogs/picture/linux_tuning_tools.png)

![Linux sar ](https://cdn.jsdelivr.net/gh/zysok2023/cloudImg/blogs/picture/linux_observability_sar.png)

## 查看所有系统变量
```shell
sysctl -a
-n：打印值时不打印关键字；
-e：忽略未知关键字错误；
-N：仅打印名称；
-w：当改变sysctl设置时使用此项；
-p：从配置文件“/etc/sysctl.conf”加载内核参数设置；
-a：打印当前所有可用的内核参数变量和值；
-A：以表格方式打印当前所有可用的内核参数变量和值。
```
## 优化性能调查
通过运行以下十个命令，您可以在 60 秒内获得系统资源使用情况和正在运行的进程的高级概念。寻找错误和饱和度指标，因为它们都很容易解释，然后寻找资源利用率。饱和是指资源的负载超过其能够处理的能力，并且可以通过请求队列的长度或等待时间来暴露。
```shell
uptime
dmesg | tail
vmstat 1
mpstat -P ALL 1
pidstat 1
iostat -xz 1
free -m
sar -n DEV 1
sar -n TCP,ETCP 1
top
```
其中一些命令需要安装 sysstat 软件包。这些命令公开的指标将帮助您完成一些USE 方法：一种定位性能瓶颈的方法。这涉及检查所有资源（CPU、内存、磁盘等）的利用率、饱和度和错误指标。还要注意何时检查并排除资源，因为通过排除过程，这会缩小研究目标，并指导任何后续调查。
### uptime
这是查看平均负载的快速方法，平均负载指示要运行的任务（进程）的数量。在 Linux 系统上，这些数字包括想要在 CPU 上运行的进程，以及在不间断 I/O（通常是磁盘 I/O）中被阻止的进程。这给出了资源负载（或需求）的高级概念，但如果没有其他工具就无法正确理解。只值得快速浏览一下。
### dmesg | tail
```shell
dmesg | tail
# [1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0
# [...]
# [1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child
# [1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB
# [2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.
```
这将查看最近 10 条系统消息（如果有）。查找可能导致性能问题的错误。上面的示例包括 oom-killer 和 TCP 丢弃请求。
### vmstat
```shell
vmstat 1
procs ---------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
34  0    0 200889792  73708 591828    0    0     0     5    6   10 96  1  3  0  0
```
r ：在 CPU 上运行并等待轮流的进程数。这提供了比负载平均值更好的信号来确定 CPU 饱和度，因为它不包括 I/O。解释一下：“r”值大于 CPU 计数就是饱和。
free ：可用内存（以千字节为单位）。如果数字太多而无法计数，则说明您有足够的可用内存。命令 7 中包含的“free -m”命令更好地解释了可用内存的状态。
si, so ：换入和换出。如果这些不为零，则说明内存不足。
us、sy、id、wa、st ：这些是所有 CPU 的平均 CPU 时间细分。它们是用户时间、系统时间（内核）、空闲、等待 I/O 和窃取时间（由其他来宾或使用 Xen，来宾自己的隔离驱动程序域）。
CPU 时间细分将通过添加用户 + 系统时间来确认 CPU 是否繁忙。恒定程度的等待 I/O 表明存在磁盘瓶颈；这是 CPU 空闲的地方，因为任务被阻塞等待挂起的磁盘 I/O。您可以将等待 I/O 视为 CPU 空闲的另一种形式，它可以提供有关它们空闲原因的线索。
I/O 处理需要系统时间。系统平均时间较高（超过 20%），进一步探索可能会很有趣：也许内核正在低效地处理 I/O。

### mpstat -P ALL 1
```shell
 mpstat -P ALL 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)

07:38:49 PM  CPU   %usr  %nice   %sys %iowait   %irq  %soft  %steal  %guest  %gnice  %idle
07:38:50 PM  all  98.47   0.00   0.75    0.00   0.00   0.00    0.00    0.00    0.00   0.78
```
此命令打印每个 CPU 的 CPU 时间细分，可用于检查不平衡情况。单个热 CPU 可以作为单线程应用程序的证据。
### pidstat 1
```shell
pidstat 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_ (32 CPU)

07:39:01 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
07:39:02 PM     0     9286    0.52    0.00    0.00    0.52     0  kworker/0:0H
```
pidstat 有点像 top 的每个进程摘要，但打印滚动摘要而不是清除屏幕。这对于观察一段时间内的模式以及将您所看到的内容（复制粘贴）记录到您的调查记录中非常有用。
### iostat -xz 1
```shell
$ iostat -xz 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          73.96    0.00    3.73    0.03    0.06   22.21

Device:   rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
xvda        0.00     0.23    0.21    0.18     4.52     2.08    34.37     0.00    9.98   13.80    5.42   2.44   0.09
```
这是了解块设备（磁盘）、所应用的工作负载和产生的性能的绝佳工具。寻找：
r/s、w/s、rkB/s、wkB/s ：这些是每秒向设备传送的读取、写入、读取千字节数和写入千字节数。使用它们来表征工作负载。性能问题可能仅仅是由于施加了过多的负载。
wait ：I/O 的平均时间（以毫秒为单位）。这是应用程序遭受的时间，因为它包括排队时间和服务时间。大于预期的平均时间可能表明设备饱和或设备出现问题。
%util ：设备利用率。这确实是一个忙碌百分比，显示设备每秒工作的时间。大于 60% 的值通常会导致性能较差（这应该在等待中看到），尽管这取决于设备。接近 100% 的值通常表示饱和。
如果存储设备是逻辑磁盘设备，面对许多后端磁盘，那么100%利用率可能只是意味着某些I/O正在100%的时间处理，但是后端磁盘可能远未饱和，并且也许能够处理更多的工作。
磁盘 I/O 性能不佳不一定是应用程序问题。许多技术通常用于异步执行 I/O，以便应用程序不会阻塞并直接遭受延迟（例如，读取时预读，写入时缓冲）。
### free -m
```shell
$ free -m
             total       used       free     shared    buffers     cached
Mem:        245998      24545     221453         83         59        541
-/+ buffers/cache:      23944     222053
Swap:            0          0          0
```
buffers ：用于缓冲区高速缓存，用于块设备 I/O。
cached ：用于页面缓存，由文件系统使用。
### sar -n DEV 1
```shell
$ sar -n DEV 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015     _x86_64_    (32 CPU)

12:16:48 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.00
```
使用此工具检查网络接口吞吐量：rxkB/s 和 txkB/s，作为工作负载的度量，并检查是否已达到任何限制。在上面的示例中，eth0 接收速度达到 22 Mbytes/s，即 176 Mbits/秒（远低于 1 Gbit/秒的限制）。
### sar -n TCP,ETCP 1
```shell
$ sar -n TCP,ETCP 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)

12:17:19 AM  active/s passive/s    iseg/s    oseg/s
12:17:20 AM      1.00      0.00  10233.00  18846.00
```
这是一些关键 TCP 指标的汇总视图。这些包括：
active/s ：每秒本地发起的 TCP 连接数（例如，通过 connect())
Passive/s ：每秒远程发起的 TCP 连接数（例如，通过accept())。
retrans/s ：每秒 TCP 重传次数。
主动和被动计数通常可用于粗略测量服务器负载：新接受的连接数（被动）和下游连接数（主动）。将主动视为出站，将被动视为入站可能会有所帮助，但这并不完全正确（例如，考虑本地主机到本地主机的连接）。
重传是网络或服务器问题的迹象；它可能是一个不可靠的网络（例如，公共互联网），或者可能是由于服务器过载并丢失数据包。上面的示例显示每秒仅一个新的 TCP 连接。
### top
```shell
$ top
top - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92
Tasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie
%Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffers
KiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem

   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java
 ```
top 命令包含我们之前检查过的许多指标。运行它可以很方便地查看是否有任何内容与之前的命令有很大不同，这表明负载是可变的。

## 内核参数
网络相关的内核参数，net.* 中常用的
非网络相关的，如fs.* kernel.* 等等
### 网络相关内核参数
[网络相关内核参数](https://code2life.top/2020/01/22/0036-linux-kernel-param/)

### 内核参数调整
**vm.min_free_kbytes**
用于控制系统中保留的最小空闲内存量，以确保内核有足够的内存来管理关键任务，例如交换、文件系统缓存等。调整这个参数可以帮助避免系统出现内存不足导致的死锁情况，但设置不当也可能浪费内存资源。

**vm.panic_on_oom**
用来控制系统在出现 "Out of Memory" (OOM) 条件时的行为。具体来说，它决定了当系统内存耗尽且无法通过其他手段释放内存时，内核是否应该触发一个内核恐慌（Kernel Panic）
0（默认值）：适用于大多数系统，因为 OOM Killer 能够在内存耗尽时自动终止占用大量内存的进程，避免系统崩溃。这个设置适合桌面系统、开发服务器、容器化环境等需要高可用性但不希望直接重启的场景。
1：适用于关键任务系统或嵌入式系统，在这些系统中，如果出现 OOM，可能意味着系统已经进入不可恢复的状态，因此直接重启可能是更好的选择。例如，在某些生产环境中，系统崩溃并重启可能比让 OOM Killer 随机终止进程并导致不确定的行为更可取。
2：适用于 NUMA（非一致性内存访问）系统，它主要用在一些高性能计算系统中。在这种配置下，你可能希望仅当特定节点的内存用完时触发内核恐慌。

vm.swappiness
用来控制内核如何平衡内存与交换空间（swap）的使用。它定义了系统在将数据从物理内存交换到交换空间时的倾向。换句话说，它决定了系统是更倾向于使用内存还是更积极地使用交换空间。
0：尽量避免使用 swap，除非物理内存已经完全耗尽。这种情况下，系统会尽量在内存中保留更多的页面。
100：尽可能多地使用 swap，这会使系统更频繁地将数据交换到交换空间，从而尽可能多地释放物理内存用于缓存和其他用途。
默认值：通常 Linux 系统的默认值是 60，这是一个平衡的设置，既不会过度使用内存，也不会频繁使用交换空间。


